{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Deeplearning [0d5bc7a0-39dd-11e9-2aab-59c8d4b467de]\n",
      "└ @ Base loading.jl:1186\n",
      "ERROR: LoadError: UndefVarError: k not defined\n",
      "Stacktrace:\n",
      " [1] top-level scope at none:0\n",
      " [2] include at ./boot.jl:326 [inlined]\n",
      " [3] include_relative(::Module, ::String) at ./loading.jl:1038\n",
      " [4] include(::Module, ::String) at ./sysimg.jl:29\n",
      " [5] top-level scope at none:2\n",
      " [6] eval at ./boot.jl:328 [inlined]\n",
      " [7] eval(::Expr) at ./client.jl:404\n",
      " [8] top-level scope at ./none:3\n",
      "in expression starting at /Users/mertceylan/git/Deeplearning.jl/src/Deeplearning.jl:1\n"
     ]
    },
    {
     "ename": "ErrorException",
     "evalue": "Failed to precompile Deeplearning [0d5bc7a0-39dd-11e9-2aab-59c8d4b467de] to /Users/mertceylan/.julia/compiled/v1.1/Deeplearning/gtjFf.ji.",
     "output_type": "error",
     "traceback": [
      "Failed to precompile Deeplearning [0d5bc7a0-39dd-11e9-2aab-59c8d4b467de] to /Users/mertceylan/.julia/compiled/v1.1/Deeplearning/gtjFf.ji.",
      "",
      "Stacktrace:",
      " [1] error(::String) at ./error.jl:33",
      " [2] compilecache(::Base.PkgId, ::String) at ./loading.jl:1197",
      " [3] _require(::Base.PkgId) at ./loading.jl:960",
      " [4] require(::Base.PkgId) at ./loading.jl:858",
      " [5] require(::Module, ::Symbol) at ./loading.jl:853",
      " [6] top-level scope at In[1]:2"
     ]
    }
   ],
   "source": [
    "using AutoGrad\n",
    "using Deeplearning\n",
    "using Plots\n",
    "import CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = CSV.read(\"datasets/digit-recognizer/train.csv\")\n",
    "# test = CSV.read(\"datasets/digit-recognizer/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d,dr = @onehot train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_normalized = nothing\n",
    "for i in 1:100\n",
    "    normalized = reshape(train[i, 2:end]./(maximum(train[i,2:end])+0.1), (28,28,1,1))\n",
    "    if train_normalized == nothing\n",
    "        train_normalized = normalized\n",
    "    else\n",
    "        train_normalized = cat(train_normalized, normalized, dims=4)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_gpu = train_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input = @cudaarray rand(28, 28, 1, 10)\n",
    "w1 = ((rand(3,3,1,6).-0.5)./100)\n",
    "w2 = ((rand(3,3,6,16).-0.5)./100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv1 = convolve(input, w1, (1,1), (1,1))\n",
    "x = conv1(input)\n",
    "@show size(x)\n",
    "pool1 = avgpool(x, (2,2), (2,2), (1,1))\n",
    "x = pool1(x)\n",
    "@show size(x)\n",
    "# conv2 = convolve(x, w2, (1,1), (1,1))\n",
    "# x = conv2(x)\n",
    "# pool2 = avgpool(x, (2,2), (2,2), (1,1))\n",
    "# x = pool2(x)\n",
    "# dense1 = dense(x, 120)\n",
    "# x = dense1(x)\n",
    "# dense2 = dense(x, 84)\n",
    "# x = dense2(x)\n",
    "# dense3 = dense(x, 10)\n",
    "# layers=[dense3,dense2,dense1,conv2,conv1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f(x) = softmax(dense3(relu(dense2(relu(dense1(pool2(relu(conv2(pool1(relu(conv1(x))))))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(train_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime f(train_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_plot = []\n",
    "loss_plot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dff(x,y) = @diff squared_diff(f(x), y)\n",
    "\n",
    "for e = 1:1\n",
    "    println(\"Epoch \", e)\n",
    "    misfits=0\n",
    "    mean_err=0\n",
    "    for i=1:size(train_gpu)[4]\n",
    "        o = f(train_gpu[:,:,:,i])\n",
    "        olabel = @onehotdecode dr o\n",
    "        \n",
    "        if(olabel == nothing || olabel!=train[i,:label])\n",
    "           misfits+=1 \n",
    "        end\n",
    "        \n",
    "        err = squared_diff(o, d[train[i,:label]])\n",
    "        mean_err+=err\n",
    "        \n",
    "        dv = dff(train_gpu[:,:,:,i], d[train[i,:label]])\n",
    "        dparams = @parameters dv\n",
    "\n",
    "        for pidx in 1:length(dparams[1:end-1])\n",
    "            dw = grad(dv, dparams[pidx])\n",
    "            layers[pidx].matrix .-=0.1*dw\n",
    "        end\n",
    "    end\n",
    "    append!(acc_plot, (1-(misfits/size(train_gpu)[4]))*100)\n",
    "    append!(loss_plot, mean_err/size(train_gpu)[4])\n",
    "end"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "dff(x,y) = @diff squared_diff(f(x), y)\n",
    "batch_size = 25\n",
    "\n",
    "for e = 1:10\n",
    "    println(\"Epoch \", e)\n",
    "    misfits=0\n",
    "    mean_err=0\n",
    "    for i=1:batch_size:size(train_gpu)[4]\n",
    "        b = train_gpu[:,:,:,i:(i+batch_size-1)]\n",
    "        o = mapslices(x->f(x),train_gpu[:,:,:,i:(i+batch_size-1)],dims=[1,2,3])\n",
    "\n",
    "        olabel = mapslices(x->decodeonehot(dr, x), o, dims=[1,2,3])[:]\n",
    "\n",
    "        misfits+=count((olabel .== nothing) .+ (olabel.!=train[1:(1+batch_size-1),:label]))\n",
    "\n",
    "        ytrues = hcat(map(x->d[x], train[1:batch_size,:label])...)\n",
    "        err = sum([squared_diff(o[:,1,1,ys], ytrues[:,ys]) for ys =1:batch_size])/batch_size\n",
    "        mean_err+=err\n",
    "                \n",
    "        dfs = [dff(train_gpu[:,:,:,eb], ytrues[:,eb]) for eb=1:batch_size]\n",
    "        dparams = [@parameters dfs[eb] for eb=1:batch_size]\n",
    "\n",
    "        dgrads = [[grad(dfs[eb],dparams[eb][ep]) for ep=1:length(dparams[eb])] for eb=1:batch_size]\n",
    "\n",
    "        catted = map(+,dgrads...)\n",
    "        \n",
    "        for pidx in 1:length(layers)\n",
    "            layers[pidx].matrix .-=0.1*catted[pidx]\n",
    "        end\n",
    "    end\n",
    "    append!(acc_plot, (1-(misfits/size(train_gpu)[4]))*100)\n",
    "    append!(loss_plot, mean_err/size(train_gpu)[4])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(acc_plot[end])\n",
    "println(loss_plot[end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot([acc_plot], linewidth=2, title=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot([loss_plot], linewidth=2, title=\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia (4 threads) 1.1.0",
   "language": "julia",
   "name": "julia-(4-threads)-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
